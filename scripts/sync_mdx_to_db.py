#!/usr/bin/env python3
"""
MDX íŒŒì¼ ì½˜í…ì¸ ë¥¼ DB articles í…Œì´ë¸”ì˜ sections í•„ë“œë¡œ ë™ê¸°í™”

ì‹¤í—˜ìš© ê¸€ì˜ placeholderë¥¼ ì‹¤ì œ ì½˜í…ì¸ ë¡œ ì—…ë°ì´íŠ¸
"""

import os
import re
import json
import psycopg2
from pathlib import Path

DB_CONFIG = {
    "host": "34.64.111.186",
    "port": 5432,
    "user": "admin",
    "password": "galddae-password",
    "database": "factcheck_db"
}

# ì‹¤í—˜ ê¸€ ìŠ¬ëŸ¬ê·¸ ëª©ë¡
EXPERIMENT_SLUGS = [
    "olive-oil-cancer-myth",
    "pre-washed-salad-danger",
    "spicy-food-dementia",
    "morning-coffee-heart-attack",
    "mouth-taping-tiktok-trend",
    "bone-smashing-dangerous",
    "8-glasses-water-myth",
    "egg-yolk-cholesterol-myth",
    "intermittent-fasting-death-risk",
    "farmed-salmon-carcinogen"
]

MDX_DIR = Path(__file__).parent.parent / "src" / "content" / "articles"


def parse_mdx_file(file_path: Path) -> dict:
    """MDX íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ frontmatterì™€ content ë¶„ë¦¬"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # frontmatter ë¶„ë¦¬ (--- ì‚¬ì´)
    parts = content.split("---", 2)
    if len(parts) >= 3:
        frontmatter_str = parts[1].strip()
        body = parts[2].strip()
    else:
        frontmatter_str = ""
        body = content

    # frontmatterì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    frontmatter = {}

    # title ì¶”ì¶œ
    title_match = re.search(r'^title:\s*["\']?(.+?)["\']?\s*$', frontmatter_str, re.MULTILINE)
    if title_match:
        frontmatter["title"] = title_match.group(1).strip('"\'')

    # description ì¶”ì¶œ
    desc_match = re.search(r'^description:\s*["\']?(.+?)["\']?\s*$', frontmatter_str, re.MULTILINE)
    if desc_match:
        frontmatter["description"] = desc_match.group(1).strip('"\'')

    # metaTitle ì¶”ì¶œ
    meta_title_match = re.search(r'^metaTitle:\s*["\']?(.+?)["\']?\s*$', frontmatter_str, re.MULTILINE)
    if meta_title_match:
        frontmatter["meta_title"] = meta_title_match.group(1).strip('"\'')

    # metaDescription ì¶”ì¶œ
    meta_desc_match = re.search(r'^metaDescription:\s*["\']?(.+?)["\']?\s*$', frontmatter_str, re.MULTILINE)
    if meta_desc_match:
        frontmatter["meta_description"] = meta_desc_match.group(1).strip('"\'')

    # sources ì¶”ì¶œ
    sources_match = re.search(r'^sources:\s*\n((?:\s+-\s+.+\n?)+)', frontmatter_str, re.MULTILINE)
    if sources_match:
        sources_text = sources_match.group(1)
        sources = []
        for line in sources_text.split("\n"):
            line = line.strip()
            if line.startswith("- "):
                source = line[2:].strip().strip('"\'')
                if source:
                    sources.append(source)
        frontmatter["sources"] = sources

    # medicalReviewer ì¶”ì¶œ
    reviewer_match = re.search(r'^medicalReviewer:\s*["\']?(.+?)["\']?\s*$', frontmatter_str, re.MULTILINE)
    if reviewer_match:
        frontmatter["medical_reviewer"] = reviewer_match.group(1).strip('"\'')

    return {
        "frontmatter": frontmatter,
        "body": body
    }


def body_to_sections(body: str) -> list:
    """ë§ˆí¬ë‹¤ìš´ ë³¸ë¬¸ì„ ì„¹ì…˜ êµ¬ì¡°ë¡œ ë³€í™˜"""
    sections = []

    # ## í—¤ë”©ìœ¼ë¡œ ë¶„í• 
    parts = re.split(r'^## (.+)$', body, flags=re.MULTILINE)

    # ì²« ë¶€ë¶„ì€ intro (í—¤ë”© ì—†ìŒ)
    if parts[0].strip():
        sections.append({
            "type": "intro",
            "heading": None,
            "content": parts[0].strip()
        })

    # ë‚˜ë¨¸ì§€ëŠ” í—¤ë”© + ì½˜í…ì¸  ìŒ
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            heading = parts[i].strip()
            content = parts[i + 1].strip()

            # FAQ ì„¹ì…˜ íŠ¹ë³„ ì²˜ë¦¬
            if "ì§ˆë¬¸" in heading.lower() or "faq" in heading.lower():
                section_type = "faq"
            elif "ê²°ë¡ " in heading.lower() or "ìš”ì•½" in heading.lower():
                section_type = "conclusion"
            elif "ê·¼ê±°" in heading.lower() or "ì—°êµ¬" in heading.lower() or "ì¦ê±°" in heading.lower():
                section_type = "evidence"
            else:
                section_type = "body"

            sections.append({
                "type": section_type,
                "heading": heading,
                "content": content
            })

    return sections


def sync_mdx_to_db():
    """MDX íŒŒì¼ë“¤ì„ DBë¡œ ë™ê¸°í™”"""
    print("ğŸš€ MDX â†’ DB ë™ê¸°í™” ì‹œì‘")

    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    try:
        updated_count = 0

        for slug in EXPERIMENT_SLUGS:
            mdx_path = MDX_DIR / f"{slug}.mdx"

            if not mdx_path.exists():
                print(f"   âš ï¸ {slug}: MDX íŒŒì¼ ì—†ìŒ")
                continue

            # MDX íŒŒì‹±
            parsed = parse_mdx_file(mdx_path)
            frontmatter = parsed["frontmatter"]
            sections = body_to_sections(parsed["body"])

            # DB ì—…ë°ì´íŠ¸
            cursor.execute("""
                UPDATE articles SET
                    title = COALESCE(%s, title),
                    description = COALESCE(%s, description),
                    meta_title = COALESCE(%s, meta_title),
                    meta_description = COALESCE(%s, meta_description),
                    sections = %s,
                    sources = COALESCE(%s, sources),
                    medical_reviewer = COALESCE(%s, medical_reviewer),
                    updated_at = NOW()
                WHERE slug = %s AND version = 'A'
            """, (
                frontmatter.get("title"),
                frontmatter.get("description"),
                frontmatter.get("meta_title"),
                frontmatter.get("meta_description"),
                json.dumps(sections, ensure_ascii=False),
                frontmatter.get("sources"),
                frontmatter.get("medical_reviewer"),
                slug
            ))

            if cursor.rowcount > 0:
                print(f"   âœ… {slug}: ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(sections)}ê°œ ì„¹ì…˜)")
                updated_count += 1
            else:
                print(f"   âš ï¸ {slug}: DBì— ê¸€ ì—†ìŒ")

        conn.commit()

        print(f"\nâœ… ë™ê¸°í™” ì™„ë£Œ: {updated_count}/{len(EXPERIMENT_SLUGS)}ê°œ ê¸€ ì—…ë°ì´íŠ¸")

    except Exception as e:
        conn.rollback()
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        cursor.close()
        conn.close()


if __name__ == "__main__":
    sync_mdx_to_db()
